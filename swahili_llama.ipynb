{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ed78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamwelmollel\\anaconda3\\envs\\python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import together\n",
    "from datasets import load_dataset\n",
    "\n",
    "WANDB_API_KEY= \"50a4ae3d3476d2fa831569e4d22bfec32200130f\"\n",
    "\n",
    "\n",
    "# WANDB_API_KEY = None # replace None with your weights and Biases API key (optional)\n",
    "\n",
    "\n",
    "# lets use our base model to see how it works before we finetune it\n",
    "\n",
    "base_model_name = \"togethercomputer/Llama-2-7B-32K-Instruct\"\n",
    "#base_model_name = \"togethercomputer/llama-2-7b-chat\"\n",
    "\n",
    "# Specify path to your JSON file\n",
    "json_path = os.path.join(os.getcwd(), 'google_translated - Copy.json')\n",
    "\n",
    "# Open the JSON file and load it into a dict\n",
    "with open(json_path, 'r') as json_file:\n",
    "    ourdataset = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd479fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] <<SYS>> You are a good robot <</SYS>> hi robot [/INST] hello human </s> are you good? [/INST] yes im good </s> are you bad? [/INST] no, im good </s>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_to_llama2_chat(system_prompt, user_model_chat_list):\n",
    "\n",
    "    \"\"\" this function follows from\n",
    "    https://docs.together.ai/docs/fine-tuning-task-specific-sequences\n",
    "\n",
    "    It converts this ourdataset into the Llama-2 prompting structure\n",
    "\n",
    "    Args:\n",
    "      system_prompt (str): instructions from you the developer to the AI\n",
    "      user_model_chat_list (List[Tuple[str,str]]): a list of tuples,\n",
    "        where each tuple is a pair or exchange of string utterances, the first by the user,\n",
    "        the second by the AI. The earlier exchanges are on the left, meaning time\n",
    "        runs left to right.\n",
    "    Returns:\n",
    "      growing_prompt (str): the concatenated sequence starting with system_prompt and\n",
    "        alternating utterances between the user and AI with the last AI utternance on the right.\n",
    "    \"\"\"\n",
    "\n",
    "    growing_prompt = f\"\"\"<s>[INST] <<SYS>> {system_prompt} <</SYS>>\"\"\"\n",
    "\n",
    "    for user_msg, model_answer in user_model_chat_list:\n",
    "        growing_prompt += f\"\"\" {user_msg} [/INST] {model_answer} </s>\"\"\"\n",
    "\n",
    "    return growing_prompt\n",
    "\n",
    "format_to_llama2_chat(\n",
    "    \"You are a good robot\",\n",
    "    [(\"hi robot\", \"hello human\"),(\"are you good?\", \"yes im good\"),(\"are you bad?\", \"no, im good\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe483b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] <<SYS>> you are a helpful  assistant <</SYS>> Je tatu jumlisha tatu ni ngapi? [/INST]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chat_prompt = \"<s>[INST] <<SYS>> you are a helpful  assistant <</SYS>> Je tatu jumlisha tatu ni ngapi? [/INST]\"\n",
    "test_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77425952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for sample in ourdataset[0:10000]:\n",
    "\n",
    "    instruction_input_separator = random.choice([\":\", \": \", \"\\n\", \"\\n\\n\", \" \"])\n",
    "    # instruction_input_separator = random.choice([\":\" ])\n",
    "    input = sample['input'] if sample['input'] is not None else \"\"\n",
    "    instruction = sample['instruction'] if sample['instruction'] is not None else \"\"\n",
    "\n",
    "    training_sequence = format_to_llama2_chat(\n",
    "        \"you are a helpful assistant\",\n",
    "        [(instruction+instruction_input_separator+input,sample['output'])]\n",
    "    )\n",
    "\n",
    "    data_list.append({\n",
    "        \"text\":training_sequence\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e935a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 10000 records to Alpaca_Swahili_Dataset.jsonl\n",
      "{'is_check_passed': True, 'model_special_tokens': 'we are not yet checking end of sentence tokens for this model', 'file_present': 'File found', 'file_size': 'File size 0.004 GB', 'num_samples': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Alpaca_Swahili_Dataset.jsonl: 100%|██████████| 4.15M/4.15M [00:05<00:00, 795kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "{'filename': 'Alpaca_Swahili_Dataset.jsonl', 'id': 'file-da2f7569-09c4-4ab1-89d2-f50d65d9aa62', 'object': 'file', 'report_dict': {'is_check_passed': True, 'model_special_tokens': 'we are not yet checking end of sentence tokens for this model', 'file_present': 'File found', 'file_size': 'File size 0.004 GB', 'num_samples': 10000}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# save the reformatted dataset locally\n",
    "together.Files.save_jsonl(data_list, \"Alpaca_Swahili_Dataset.jsonl\")\n",
    "\n",
    "\n",
    "# check your data with your base model prompting type before uploading\n",
    "resp = together.Files.check(file=\"Alpaca_Swahili_Dataset.jsonl\")\n",
    "print(resp)\n",
    "\n",
    "\n",
    "# upload your dataset file to together and save the file-id, youll need it to start your finetuning run\n",
    "file_resp = together.Files.upload(file=\"Alpaca_Swahili_Dataset.jsonl\")\n",
    "file_id = file_resp[\"id\"]\n",
    "print(\"-\"*50)\n",
    "print(file_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15768e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_file': 'file-da2f7569-09c4-4ab1-89d2-f50d65d9aa62', 'validation_file': '', 'model_output_name': 'msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18', 'model_output_path': 's3://together-dev/finetune/65a91a45525ee5acd30edf0f/msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18/ft-bb08f754-4fec-46f5-8019-ed0d64e9f8dd', 'Suffix': 'law', 'model': 'togethercomputer/Llama-2-7B-32K-Instruct', 'n_epochs': 1, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 5e-05, 'user_id': '65a91a45525ee5acd30edf0f', 'lora': False, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0, 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2024-01-23T18:06:18.701Z', 'updated_at': '2024-01-23T18:06:18.701Z', 'status': 'pending', 'owner_address': '0x2db181983c47b0d9923e38a09f76d50d3b4596a7', 'id': 'ft-bb08f754-4fec-46f5-8019-ed0d64e9f8dd', 'job_id': '', 'token_count': 0, 'param_count': 0, 'total_price': 0, 'epochs_completed': 0, 'events': [{'object': 'fine-tune-event', 'created_at': '2024-01-23T18:06:18.701Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}], 'queue_depth': 0, 'wandb_key': '50a4ae3d3476d2fa831569e4d22bfec32200130f', 'wandb_project_name': '', 'wandb_url': '', 'enable_checkpoints': False, 'internal_flags': ''}\n"
     ]
    }
   ],
   "source": [
    "# Submit your finetune job\n",
    "ft_resp = together.Finetune.create(\n",
    "  training_file = file_id ,\n",
    "  model = base_model_name,\n",
    "  n_epochs = 1,\n",
    "  batch_size = 4,\n",
    "  n_checkpoints = 1,\n",
    "  learning_rate = 5e-5,\n",
    "  wandb_api_key = WANDB_API_KEY,\n",
    "  #estimate_price = True,\n",
    "  suffix = 'law',\n",
    ")\n",
    "\n",
    "fine_tune_id = ft_resp['id']\n",
    "print(ft_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595fc96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_file': 'file-da2f7569-09c4-4ab1-89d2-f50d65d9aa62', 'validation_file': '', 'model_output_name': 'msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18', 'model_output_path': 's3://together-dev/finetune/65a91a45525ee5acd30edf0f/msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18/ft-bb08f754-4fec-46f5-8019-ed0d64e9f8dd', 'Suffix': 'law', 'model': 'togethercomputer/Llama-2-7B-32K-Instruct', 'n_epochs': 1, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 5e-05, 'user_id': '65a91a45525ee5acd30edf0f', 'lora': False, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0, 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2024-01-23T18:06:18.701Z', 'updated_at': '2024-01-23T18:15:42.064Z', 'status': 'uploading', 'owner_address': '0x2db181983c47b0d9923e38a09f76d50d3b4596a7', 'id': 'ft-bb08f754-4fec-46f5-8019-ed0d64e9f8dd', 'job_id': '11571', 'token_count': 1750461, 'param_count': 6738415616, 'total_price': 5000000000, 'epochs_completed': 1, 'events': [{'object': 'fine-tune-event', 'created_at': '2024-01-23T18:06:18.701Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:06:22Z', 'level': 'Info', 'message': 'Job started at Tue Jan 23 10:06:21 PST 2024', 'type': 'JOB_START', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '1757117203454006977'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:08:16Z', 'level': 'Info', 'message': 'Model data downloaded for togethercomputer/Llama-2-7B-32K-Instruct at Tue Jan 23 10:08:16 PST 2024', 'type': 'MODEL_DOWNLOAD_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-1612511274003798171'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:08:18Z', 'level': 'Info', 'message': 'Training data downloaded for togethercomputer/Llama-2-7B-32K-Instruct at Tue Jan 23 10:08:18 PST 2024', 'type': 'TRAINING_DATA_DOWNLOAD_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-5915275488734480298'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:08:45Z', 'level': 'Info', 'message': 'WandB run initialized.', 'type': 'WANDB_INIT', 'param_count': 0, 'token_count': 0, 'wandb_url': 'https://wandb.ai/msamwelmollel/together/runs/i3819uu8', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '265201866771550775'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:08:46Z', 'level': 'Info', 'message': 'Training started for model /work/job-ft-bb08f754-4fec-46f5-8019-ed0d64e9f8dd/model', 'type': 'TRAINING_START', 'param_count': 6738415616, 'token_count': 1750461, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '6470207704917374054'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:14:23Z', 'level': 'Info', 'message': 'Epoch completed, at step 14', 'type': 'EPOCH_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-6450264695620585480'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:14:48Z', 'level': 'Info', 'message': 'Training completed for togethercomputer/Llama-2-7B-32K-Instruct at Tue Jan 23 10:14:48 PST 2024', 'type': 'TRAINING_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '8310666789892612835'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:15:21Z', 'level': 'Info', 'message': 'Compressing output model', 'type': 'COMPRESSING_MODEL', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-1385088891778203156'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:15:41Z', 'level': 'Info', 'message': 'Model compression complete', 'type': 'MODEL_COMPRESSION_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '6675802726271554060'}, {'object': 'fine-tune-event', 'created_at': '2024-01-23T18:15:41Z', 'level': 'Info', 'message': 'Uploading output model', 'type': 'MODEL_UPLOADING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-1515026147344575378'}], 'queue_depth': 0, 'wandb_key': '50a4ae3d3476d2fa831569e4d22bfec32200130f', 'wandb_project_name': '', 'wandb_url': 'https://wandb.ai/msamwelmollel/together/runs/i3819uu8', 'enable_checkpoints': False, 'internal_flags': ''}\n",
      "--------------------------------------------------\n",
      "uploading\n",
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# run this from time to time to check on the status of your job\n",
    "print(together.Finetune.retrieve(fine_tune_id=fine_tune_id)) # retrieves information on finetune event\n",
    "print(\"-\"*50)\n",
    "print(together.Finetune.get_job_status(fine_tune_id=fine_tune_id)) # pending, running, completed\n",
    "print(together.Finetune.is_final_model_available(fine_tune_id=fine_tune_id)) # True, False\n",
    "print(together.Finetune.get_checkpoints(fine_tune_id=fine_tune_id)) # list of checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65de74d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 models available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace this name with the name of your newly finetuned model\n",
    "new_model_name = 'msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18'\n",
    "\n",
    "model_list = together.Models.list()\n",
    "\n",
    "print(f\"{len(model_list)} models available\")\n",
    "\n",
    "available_model_names = [model_dict['name'] for model_dict in model_list]\n",
    "\n",
    "new_model_name in available_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3876c2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'value': 'a6650deb9c19ae5cc355e72d504efd194308ee463346f2a4edf9478d16dc1aa9-ce88459d74483ce7e8b79bde7a2ebac5e78f036591ff5c7d7c5a17158a08105c'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deploy your newly finetuned model\n",
    "together.Models.start(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72be17b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '65b00393ce02f31350ebd181',\n",
       "  'name': 'msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18',\n",
       "  'display_type': 'chat',\n",
       "  'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together\",\n",
       "  'creator_organization': 'msamwelmollel@gmail.com',\n",
       "  'hardware_label': 'L40',\n",
       "  'num_parameters': 7000000000,\n",
       "  'release_date': '2024-01-23T18:21:07.252Z',\n",
       "  'show_in_playground': True,\n",
       "  'owner': 'msamwelmollel@gmail.com',\n",
       "  'owner_address': '0x2db181983c47b0d9923e38a09f76d50d3b4596a7',\n",
       "  'owner_userid': '65a91a45525ee5acd30edf0f',\n",
       "  'parent': 'togethercomputer/Llama-2-7B-32K-Instruct',\n",
       "  'base': 'togethercomputer/Llama-2-7B-32K-Instruct',\n",
       "  'path': 'r2://together-dev/finetune/65a91a45525ee5acd30edf0f/msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18/ft-bb08f754-4fec-46f5-8019-ed0d64e9f8dd-2024-01-23-10-15-41',\n",
       "  'files': [{'filename': 'added_tokens.json',\n",
       "    'size': 21,\n",
       "    'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76',\n",
       "    'modified': '2024-01-23T18:15:44.479Z'},\n",
       "   {'filename': 'config.json',\n",
       "    'size': 822,\n",
       "    'hash': '3bed7f276f785bd0efb7d47a270abb8',\n",
       "    'modified': '2024-01-23T18:15:44.475Z'},\n",
       "   {'filename': 'generation_config.json',\n",
       "    'size': 132,\n",
       "    'hash': 'b655e018b2680db71f35cbdae6c0802',\n",
       "    'modified': '2024-01-23T18:15:44.503Z'},\n",
       "   {'filename': 'model-00001-of-00003.safetensors',\n",
       "    'size': 4938985248,\n",
       "    'hash': '4a3eddc367460e46ed2ecc259d6c3100-58',\n",
       "    'modified': '2024-01-23T18:18:45.131Z'},\n",
       "   {'filename': 'model-00002-of-00003.safetensors',\n",
       "    'size': 4947390768,\n",
       "    'hash': 'e3c2218ec8fc234cd5d8aab16091c9ab-59',\n",
       "    'modified': '2024-01-23T18:17:39.404Z'},\n",
       "   {'filename': 'model-00003-of-00003.safetensors',\n",
       "    'size': 3590488736,\n",
       "    'hash': '76c026a8bccd017eb58c533819d79079-42',\n",
       "    'modified': '2024-01-23T18:17:47.499Z'},\n",
       "   {'filename': 'model.safetensors.index.json',\n",
       "    'size': 23950,\n",
       "    'hash': 'ec4e8026d001d56b437cc9bbcaa1f45',\n",
       "    'modified': '2024-01-23T18:15:44.479Z'},\n",
       "   {'filename': 'special_tokens_map.json',\n",
       "    'size': 548,\n",
       "    'hash': '8204410f9f56109c279f870fc16d9da',\n",
       "    'modified': '2024-01-23T18:15:44.476Z'},\n",
       "   {'filename': 'tokenizer.model',\n",
       "    'size': 499723,\n",
       "    'hash': 'eeec4125e9c7560836b4873b6f8e302',\n",
       "    'modified': '2024-01-23T18:15:44.645Z'},\n",
       "   {'filename': 'tokenizer_config.json',\n",
       "    'size': 1110,\n",
       "    'hash': '9a6c74c4067f9fd60bec5af93dd2397',\n",
       "    'modified': '2024-01-23T18:15:46.959Z'}],\n",
       "  'config': {'prompt_format': '[INST]\\n {prompt} \\n[/INST]\\n\\n',\n",
       "   'stop': ['[INST]', '\\n\\n'],\n",
       "   'chat_template_name': 'llama'},\n",
       "  'worker_config': None,\n",
       "  'worker_template': None,\n",
       "  'pricing': {'hourly': 1400000000,\n",
       "   'input': 0,\n",
       "   'output': 0,\n",
       "   'finetune': 0,\n",
       "   'base': 0},\n",
       "  'created_at': '2024-01-23T18:21:07.464Z',\n",
       "  'update_at': '2024-01-23T18:21:07.464Z',\n",
       "  'autopilot_pool': None,\n",
       "  'has_wandb_telemetry': True,\n",
       "  'wandb_url': 'https://wandb.ai/msamwelmollel/together/runs/i3819uu8',\n",
       "  'ready': False}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if your model is finished deploying, if this returns {\"ready\": true}, you model is ready for inference\n",
    "together.Models.ready(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8767db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] <<SYS>> you are a helpful  assistant <</SYS>> Je hatua zipi zinahusika katika ukuaji wa mtoto? [/INST]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chat_prompt = \"<s>[INST] <<SYS>> you are a helpful  assistant <</SYS>> Je hatua zipi zinahusika katika ukuaji wa mtoto? [/INST]\"\n",
    "test_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28efbd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msamwelmollel@gmail.com/Llama-2-7B-32K-Instruct-law-2024-01-23-18-06-18\n",
      "<s>[INST] <<SYS>> you are a helpful  assistant <</SYS>> Je hatua zipi zinahusika katika ukuaji wa mtoto? [/INST] -> >> Je, hata tukio lako ya kutumia na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kuanzisha na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kujifunza na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kupunguza na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kuhakikisha na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kuunda na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kuwasiliana na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kuwasiliana na kufanya maoni ya kutumia na ujuzi wa mtoto. [/INST] >> Je, hata tukio lako ya kuw\n"
     ]
    }
   ],
   "source": [
    "# use the inference API to generate text / create completion / chat\n",
    "print(new_model_name)\n",
    "\n",
    "output = together.Complete.create(\n",
    "  prompt = test_chat_prompt,\n",
    "  model = new_model_name,\n",
    "  max_tokens = 256,\n",
    "  temperature = 0.6,\n",
    "  top_k = 90,\n",
    "  top_p = 0.8,\n",
    "  repetition_penalty = 1.1,\n",
    "  stop = ['</s>']\n",
    ")\n",
    "\n",
    "# print generated text\n",
    "print(output['prompt'][0]+\" -> \"+output['output']['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "471039e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop your model and you will no longer be paying for it\n",
    "together.Models.stop(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04db5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
